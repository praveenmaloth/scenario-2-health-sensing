
---

#  Scenario-2: Health Sensing — Breathing Event Detection

### *My work for the IIT Gandhinagar Health-Sensing Internship Task (2025)*

This repository contains everything **I have completed so far** for Scenario-2 of the Earth & Health Sensing internship task.
In this scenario, I am working with **physiological signals** (Flow, Thorax, SPO2, and Event annotations) to generate a **machine-learning-ready dataset** for detecting breathing abnormalities such as:

* **Hypopnea**
* **Obstructive Apnea**
* **Normal breathing**

My current progress includes:

✔ Parsing raw sensor files
✔ Cleaning & filtering signals
✔ 30-second sliding-window segmentation
✔ Event-based labeling
✔ Feature extraction
✔ Dataset generation pipeline
✔ Scripts organized properly
✔ GitHub repo + Drive data setup complete

---

#  Project Structure

```
health-sensing/
│
├── scripts/
│   ├── create_dataset.py     # Dataset generation (my main pipeline)
│   ├── vis.py                # For visualizing signals
│
├── Data/                     # Raw signals (stored in Google Drive)
│   ├── AP01/
│   ├── AP02/
│   └── ...
│
├── Dataset/                  # Output CSV generated by my script
│
└── .gitignore                # Data folders excluded from GitHub
```

> **Note**:
> I am NOT uploading the raw physiological data to GitHub because the files are extremely large.
> They remain safely stored in my Drive and are ignored via `.gitignore`.

---

#  Data Format I Worked With

Each participant folder (AP01, AP02, ...) contains:

* **Flow .txt**
* **Flow Events .txt**
* **Thorax .txt**
* **SPO2 .txt**
* **Sleep profile**

Example flow snippet:

```
Signal Type: Flow_TH_Type
Sample Rate: 32

30.05.2024 20:59:00,000; 120
30.05.2024 20:59:00,031; 120
...
```

Example event snippet:

```
30.05.2024 23:48:45,119-23:49:01,408; 16; Hypopnea; N1
```

My scripts handle irregular spacing, timestamps, inconsistent semicolons, and missing headers.

---

#  What I Implemented

## 1️ Parsing

I wrote robust parsers that extract:

* timestamps
* numerical values
* event start/end times
* labels

They handle different formats and messy text.

---

## 2️ Filtering

I cleaned the Flow + Thoracic signals using a **bandpass filter**:

```
Low cutoff: 0.07 Hz  
High cutoff: 0.8 Hz  
Order: 3  
```

SPO2 is smoothed with a simple rolling average.

---

## 3️ Window Segmentation

I split signals into **30-second windows** with **50% overlap**:

```
[0–30s], [15–45s], [30–60s]...
```

For each window, I extracted:

* Flow segment
* Thorax segment
* SPO2 segment

---

## 4️ Feature Engineering

For each signal and each window, I compute:

* mean
* standard deviation
* minimum
* maximum
* RMS

Feature columns look like:

```
flow_mean, flow_std, thor_mean, spo2_rms, ...
```

---

## 5️ Event-Based Labeling

I gave each window a label based on >50% overlap with event:

* **Obstructive Apnea**
* **Hypopnea**
* **Normal**

This ensures labels match clinically-defined criteria.

---

## 6️ Final Output

My script produces a CSV like:

```
Dataset/breathing_dataset.csv
```

Each row = **1 window** with features + label.

This is the dataset that will be used for ML classification in the next stage.

---

#  How I Run My Pipeline (Colab)

### Visualize signals:

```bash
!python scripts/vis.py -name "/content/drive/MyDrive/health-sensing/Data"
```

### Create final dataset:

```bash
!python scripts/create_dataset.py \
    -in_dir "/content/drive/MyDrive/health-sensing/Data" \
    -out_dir "/content/drive/MyDrive/health-sensing/Dataset"
```

---

#  What I Will Do Next

I have completed the **entire dataset generation pipeline**.
Next steps:

* Build ML model (CNN, LSTM, or Random Forest)
* Evaluate accuracy, F1-score
* Generate confusion matrix
* Add training notebook
* Upload final results

I will update this repository as I progress.

---

